// src/pages/VoiceInterview.tsx
import React, { useState } from 'react';
import RecordingButton from '../components/RecordingButton';
import ChatHistory from '../components/ChatHistory';
import type { ChatMessage } from '../components/ChatHistory';
import { sendAudioToNodeBackend } from '../api/api';

// Gi·∫£ ƒë·ªãnh b·∫°n c√≥ c√°c component layout (Navbar, Footer)
import Navbar from '../components/Navbar'; 
import Footer from '../components/Footer';

// H√†m mock/placeholder cho Navbar
const mockScrollToSection = (id: string, tab?: "hiragana" | "katakana") => {
    console.log(`Scrolling to ${id}`);
};

const VoiceInterview: React.FC = () => {
  const [messages, setMessages] = useState<ChatMessage[]>([]);
  const [isProcessing, setIsProcessing] = useState(false);

  const handleRecordingComplete = async (audioBlob: Blob) => {
    if (isProcessing) return;

    setIsProcessing(true);
    let messageId = Date.now();
    
    // 1. Th√™m tin nh·∫Øn ng∆∞·ªùi d√πng v√†o l·ªãch s·ª≠
    const userText = `(ƒê√£ g·ª≠i ${Math.round(audioBlob.size / 1024)} KB audio. Ch·ªù AI tr·∫£ l·ªùi...)`; 
    setMessages(prev => [...prev, { id: messageId++, sender: 'user', text: userText }]);

    try {
      // 2. G·ª≠i audio ƒë·∫øn Node.js backend
      const { text, audioBase64 } = await sendAudioToNodeBackend(audioBlob);

      // 3. Th√™m tin nh·∫Øn tr·∫£ l·ªùi t·ª´ AI v√†o l·ªãch s·ª≠
      setMessages(prev => [...prev, { 
        id: messageId++, 
        sender: 'ai', 
        text: text, 
        audioBase64: audioBase64 
      }]);

    } catch (error) {
      console.error("L·ªói khi giao ti·∫øp v·ªõi backend AI:", error);
      // Hi·ªÉn th·ªã th√¥ng b√°o l·ªói
      setMessages(prev => [...prev, { 
        id: messageId++, 
        sender: 'ai', 
        text: 'L·ªói: Kh√¥ng th·ªÉ k·∫øt n·ªëi ho·∫∑c x·ª≠ l√Ω y√™u c·∫ßu. Vui l√≤ng ki·ªÉm tra Node.js backend (c·ªïng 5000).', 
      }]);
    } finally {
      setIsProcessing(false);
    }
  };

  return (
    <div className="flex flex-col min-h-screen">
        <Navbar 
            scrollToSection={mockScrollToSection} 
            onAuthClick={() => {}} 
            userDropdownOpen={false} 
            setUserDropdownOpen={() => {}} 
        />
        
        <main className="flex-1 p-4 sm:p-8 max-w-2xl mx-auto w-full flex flex-col">
            <h1 className="text-3xl font-bold text-center mb-6 text-gray-800">
                üó£Ô∏è Tr·ª£ L√Ω Luy·ªán N√≥i AI (Ph·ªèng V·∫•n)
            </h1>
            
            {/* Khu v·ª±c L·ªãch s·ª≠ Chat */}
            <ChatHistory messages={messages} />

            {/* Khu v·ª±c Ghi √Çm v√† T∆∞∆°ng t√°c */}
            <div className="mt-6 p-4 border-t bg-white sticky bottom-0">
                <div className="flex justify-center">
                    <RecordingButton 
                        onRecordingComplete={handleRecordingComplete} 
                        isProcessing={isProcessing}
                    />
                </div>
                
                {isProcessing && (
                    <p className="text-center text-sm mt-2 text-blue-600">
                        AI ƒëang ph√¢n t√≠ch v√† t·∫°o c√¢u tr·∫£ l·ªùi...
                    </p>
                )}
            </div>
        </main>
        <Footer />
    </div>
  );
};

export default VoiceInterview;